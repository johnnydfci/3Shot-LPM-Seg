{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Define directories\n",
    "data_dir = './videos/MRI515_T2'\n",
    "label_dir = os.path.join(data_dir, 'label_in_png_L4L5_renamed')\n",
    "\n",
    "prompt_dir = 'manual_prompt_frame0_1_2'\n",
    "prompt_dir = 'manual_prompt_frame0_1'\n",
    "prompt_dir = 'manual_prompt_frame0'\n",
    "\n",
    "# Directory containing auto-segmentation results (using the \"nolap\" version)\n",
    "auto_seg_dir = os.path.join(data_dir, prompt_dir, 'SAM2_seg_mask_nolap')\n",
    "\n",
    "# Output CSV file path (final long-format results)\n",
    "csv_write_path = os.path.join(data_dir, prompt_dir, prompt_dir + '_area_results_long.csv')\n",
    "\n",
    "# Check if required directories exist\n",
    "if not os.path.exists(label_dir) or not os.path.exists(auto_seg_dir):\n",
    "    raise FileNotFoundError(\"One or more required directories do not exist!\")\n",
    "\n",
    "# Each pixel corresponds to the actual area (e.g., unit in square millimeters)\n",
    "spacing_factor = 0.6875 * 0.6875  # = 0.47265625\n",
    "\n",
    "# Define target pixel values corresponding to 4 classes\n",
    "classes = [50, 100, 150, 200]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each label file\n",
    "for label_file in os.listdir(label_dir):\n",
    "    # Assume file name format is \"123.png\", extract numeric part as index\n",
    "    try:\n",
    "        label_index = int(os.path.splitext(label_file)[0])\n",
    "    except ValueError:\n",
    "        print(f\"Skipping file with non-numeric name: {label_file}\")\n",
    "        continue\n",
    "\n",
    "    # Construct full path for label file\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "    label_index = str(int(label_index))\n",
    "    \n",
    "    # Construct full paths for auto-segmentation masks (4 classes)\n",
    "    auto_seg_paths = [\n",
    "        os.path.join(auto_seg_dir, f\"frame_{label_index}_obj_{i}.png\")\n",
    "        for i in range(1, len(classes) + 1)\n",
    "    ]\n",
    "    \n",
    "    # Check if all auto-segmentation files exist\n",
    "    if not all(os.path.exists(p) for p in auto_seg_paths):\n",
    "        print(f\"Auto segmentation files missing for {label_file}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read label mask\n",
    "    label_mask = np.array(Image.open(label_path))\n",
    "\n",
    "    # Read all auto-segmentation masks\n",
    "    auto_masks = [np.array(Image.open(p)) for p in auto_seg_paths]\n",
    "\n",
    "    file_result = {\"file_name\": label_file}\n",
    "\n",
    "    # Compute area for each class\n",
    "    for idx, class_val in enumerate(classes, start=1):\n",
    "        # Label: Apply threshold, select pixels close to the target value (e.g., ±10)\n",
    "        label_class_mask = (np.abs(label_mask - class_val) < 10).astype(np.uint8)\n",
    "        \n",
    "        # Auto segmentation: Corresponding obj_i file, using the same threshold condition\n",
    "        auto_class_mask = (np.abs(auto_masks[idx - 1] - class_val) < 10).astype(np.uint8)\n",
    "        \n",
    "        # Resize auto-segmentation mask to match label mask\n",
    "        target_size = (label_mask.shape[1], label_mask.shape[0])\n",
    "        auto_class_mask = cv2.resize(auto_class_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Compute area: non-zero pixel count × spacing_factor\n",
    "        label_area = np.sum(label_class_mask) * spacing_factor\n",
    "        auto_area  = np.sum(auto_class_mask)  * spacing_factor\n",
    "\n",
    "        # Store results with keys such as \"class1_label_area\", \"class1_auto_area\"\n",
    "        file_result[f\"class{idx}_label_area\"] = label_area\n",
    "        file_result[f\"class{idx}_auto_area\"] = auto_area\n",
    "\n",
    "    results.append(file_result)\n",
    "    \n",
    "    # Print processing results\n",
    "    print(f\"Processed {label_file}:\", end=\" \")\n",
    "    for idx in range(1, len(classes) + 1):\n",
    "        print(f\"Class{idx} -> Label: {file_result[f'class{idx}_label_area']:.2f}, Auto: {file_result[f'class{idx}_auto_area']:.2f}; \", end=\"\")\n",
    "    print()\n",
    "\n",
    "# Convert wide-format results to long format\n",
    "rows = []\n",
    "for res in results:\n",
    "    pid = os.path.splitext(res[\"file_name\"])[0]  # Use file name (without extension) as PID\n",
    "    for cls in range(1, len(classes) + 1):\n",
    "        rows.append({\n",
    "            \"PID\": pid,\n",
    "            \"Class\": cls,\n",
    "            \"Auto Area\": res[f\"class{cls}_auto_area\"],\n",
    "            \"Manual Area\": res[f\"class{cls}_label_area\"]\n",
    "        })\n",
    "\n",
    "results_long_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save long-format results to CSV\n",
    "results_long_df.to_csv(csv_write_path, index=False)\n",
    "print(f\"Results saved to {csv_write_path}\")\n",
    "\n",
    "# Output preview\n",
    "print(results_long_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3336a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14118ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_prompt_id = ['00000', '00001', '00002']\n",
    "\n",
    "# Logic: Determine which prefixes to remove from manual_prompt_id based on whether \"1\" or \"2\" is in prompt_dir\n",
    "remove_prefixes = manual_prompt_id[: 1 + (\"1\" in prompt_dir) + (\"2\" in prompt_dir)]\n",
    "print(\"Remove prefixes:\", remove_prefixes)\n",
    "\n",
    "# Filter function to remove rows where \"PID\" starts with any of the specified prefixes\n",
    "filter_pid = lambda df: df[~df[\"PID\"].astype(str).str.startswith(tuple(remove_prefixes))]\n",
    "\n",
    "# Apply filtering\n",
    "results_df = filter_pid(results_long_df)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from scipy.stats import ttest_ind, ks_2samp, shapiro\n",
    "\n",
    "# Assuming df_results already contains the segmentation area calculation results\n",
    "# and includes columns like \"PID\", \"Class\", \"Manual Area\", \"Auto Area\", etc.\n",
    "\n",
    "# ----------------- Statistical Tests, MAPE, and ICC -----------------\n",
    "# Lists to store MAPE and ICC results for each class\n",
    "mape_results = []  # Format: [Class, MAPE, MAPE_std]\n",
    "icc_results = []   # Format: [Class, ICC, ICC_95%_CI_Lower, ICC_95%_CI_Upper]\n",
    "# Dictionary to store p-values for each class\n",
    "p_value_dict = {}\n",
    "\n",
    "df_results = results_df\n",
    "\n",
    "# Perform statistical tests, error analysis, and ICC calculations for each class\n",
    "for class_value in [1, 2, 3, 4]:\n",
    "    df_class = df_results[df_results[\"Class\"] == class_value]\n",
    "    if df_class.empty:\n",
    "        continue\n",
    "\n",
    "    # Extract manual segmentation (Manual Area) and automatic segmentation (Auto Area) values\n",
    "    label_values = df_class[\"Manual Area\"].values * 100\n",
    "    auto_values = df_class[\"Auto Area\"].values * 100\n",
    "\n",
    "    # -------------- Normality Test --------------\n",
    "    shapiro_label = shapiro(label_values)\n",
    "    shapiro_auto_seg = shapiro(auto_values)\n",
    "\n",
    "    label_is_normal = shapiro_label.pvalue >= 0.05\n",
    "    auto_seg_is_normal = shapiro_auto_seg.pvalue >= 0.05\n",
    "\n",
    "    print(f\"\\nClass {class_value}:\")\n",
    "    print(f\"  Shapiro-Wilk Normality Test (Manual): p-value = {shapiro_label.pvalue:.3f} -> {'Normal' if label_is_normal else 'Non-Normal'}\")\n",
    "    print(f\"  Shapiro-Wilk Normality Test (Auto-Seg): p-value = {shapiro_auto_seg.pvalue:.3f} -> {'Normal' if auto_seg_is_normal else 'Non-Normal'}\")\n",
    "\n",
    "    # -------------- Select Statistical Test Method --------------\n",
    "    if label_is_normal and auto_seg_is_normal:\n",
    "        t_stat, p_value = ttest_ind(label_values, auto_values, equal_var=False)\n",
    "        print(\"  Method: Independent Two-Sample T-Test\")\n",
    "        print(f\"  T-statistic: {t_stat:.4f}, P-value: {p_value:.3f}\")\n",
    "    else:\n",
    "        ks_stat, p_value = ks_2samp(label_values, auto_values)\n",
    "        print(\"  Method: Kolmogorov-Smirnov Test\")\n",
    "        print(f\"  KS-statistic: {ks_stat:.4f}, P-value: {p_value:.3f}\")\n",
    "\n",
    "    # Store p-value for later summary\n",
    "    p_value_dict[class_value] = p_value\n",
    "\n",
    "    # -------------- Interpret Test Results --------------\n",
    "    if p_value < 0.05:\n",
    "        print(\"  - Significant difference detected (p < 0.05).\")\n",
    "    else:\n",
    "        print(\"  - No significant difference detected (p >= 0.05).\")\n",
    "\n",
    "    # -------------- Compute MAPE --------------\n",
    "    # Avoid division by zero using a small epsilon\n",
    "    epsilon = 1e-6\n",
    "    ape = np.abs((auto_values - label_values) / (label_values + epsilon))\n",
    "    mape = np.mean(ape)\n",
    "    mape_std = np.std(ape)\n",
    "    mape_results.append([class_value, mape, mape_std])\n",
    "\n",
    "    # -------------- Compute ICC --------------\n",
    "    df_long = df_class.melt(id_vars=[\"PID\"], value_vars=[\"Manual Area\", \"Auto Area\"],\n",
    "                            var_name=\"Method\", value_name=\"Area\")\n",
    "    icc_df = pg.intraclass_corr(data=df_long, targets=\"PID\", raters=\"Method\", ratings=\"Area\")\n",
    "    # Extract the row corresponding to ICC2\n",
    "    icc_row = icc_df[icc_df[\"Type\"] == \"ICC2\"].iloc[0]\n",
    "    icc_value = icc_row[\"ICC\"]\n",
    "    if \"CI95%\" in icc_row:\n",
    "        ci_lower, ci_upper = icc_row[\"CI95%\"]\n",
    "    else:\n",
    "        ci_lower, ci_upper = np.nan, np.nan\n",
    "    icc_results.append([class_value, icc_value, ci_lower, ci_upper])\n",
    "\n",
    "# ----------------- Display MAPE and ICC Results -----------------\n",
    "mape_df = pd.DataFrame(mape_results, columns=['Class', 'MAPE', 'MAPE_std'])\n",
    "icc_df = pd.DataFrame(icc_results, columns=['Class', 'ICC', 'ICC_95%_CI_Lower', 'ICC_95%_CI_Upper'])\n",
    "\n",
    "# Convert MAPE and its standard deviation to percentage format (rounded to one decimal place)\n",
    "mape_df['MAPE'] = (mape_df['MAPE'] * 100).round(1)\n",
    "mape_df['MAPE_std'] = (mape_df['MAPE_std'] * 100).round(1)\n",
    "\n",
    "mape_df = mape_df.sort_values(by=\"Class\")\n",
    "icc_df = icc_df.sort_values(by=\"Class\")\n",
    "\n",
    "# Print MAPE results in the format: 14.9 ± 13.1%\n",
    "print(\"\\n### MAPE Results ###\")\n",
    "for _, row in mape_df.iterrows():\n",
    "    print(f\"Class {int(row['Class'])}: {row['MAPE']} ± {row['MAPE_std']}%\")\n",
    "\n",
    "# Print ICC results (including 95% confidence interval)\n",
    "print(\"\\n### ICC Results ###\")\n",
    "for _, row in icc_df.iterrows():\n",
    "    print(f\"Class {int(row['Class'])}: {row['ICC']:.3f}, [{row['ICC_95%_CI_Lower']:.2f} - {row['ICC_95%_CI_Upper']:.2f}]\")\n",
    "\n",
    "# ----------------- Summary of p-values -----------------\n",
    "# Define class names (adjust if necessary)\n",
    "class_label_mapping = {\n",
    "    1: \"Right LES\",\n",
    "    2: \"Right MF\",\n",
    "    3: \"Left MF\",\n",
    "    4: \"Left LES\"\n",
    "}\n",
    "print(\"\\n### p-values Summary ###\")\n",
    "# Print first row: Class names with corresponding numbers\n",
    "header = \" \".join([f\"{class_label_mapping[cv]} {cv}\" for cv in [1, 2, 3, 4]])\n",
    "# Print second row: Corresponding p-values rounded to three decimals\n",
    "p_values_line = \" \".join([f\"{p_value_dict.get(cv, np.nan):.3f}\" for cv in [1, 2, 3, 4]])\n",
    "print(header)\n",
    "print(p_values_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c10d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sam2]",
   "language": "python",
   "name": "conda-env-sam2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
